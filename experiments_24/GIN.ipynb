{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, roc_auc_score,\n",
    "                             precision_recall_curve)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import GINConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_graph(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['group_list'] = df['group_list'].apply(ast.literal_eval)\n",
    "    \n",
    "    group_dict = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        user_id = row['id']\n",
    "        for group in row['group_list']:\n",
    "            for group_id, message_count in group.items():\n",
    "                group_dict.setdefault(group_id, []).append((user_id, message_count))\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        node_id = row['id']\n",
    "        attributes = row.drop('group_list').to_dict()\n",
    "        G.add_node(node_id, **attributes)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_features(G):\n",
    "    features = []\n",
    "    for node in G.nodes():\n",
    "        node_data = G.nodes[node]\n",
    "        vector = [\n",
    "            node_data.get('groups'),\n",
    "            node_data.get('number_of_messages'),\n",
    "            node_data.get('texts'),\n",
    "            node_data.get('text_ratio'),\n",
    "            node_data.get('midia'),\n",
    "            node_data.get('midia_ratio'), \n",
    "            node_data.get('virals'),\n",
    "            node_data.get('repeated_messages'),\n",
    "            node_data.get('strenght'),\n",
    "            node_data.get('viral_strenght')\n",
    "        ]\n",
    "        features.append(vector)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 5364\n",
      "Number of edges: 0\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'users_selected_features.csv'\n",
    "graph = create_message_graph(csv_file_path)\n",
    "\n",
    "print(f'Number of nodes: {graph.number_of_nodes()}')\n",
    "print(f'Number of edges: {graph.number_of_edges()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg_data = from_networkx(graph)\n",
    "node_features = extract_node_features(graph)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_normalized = scaler.fit_transform(node_features)\n",
    "X = torch.tensor(X_normalized, dtype=torch.float)\n",
    "\n",
    "labels = torch.tensor([graph.nodes[node]['disinformer'] for node in graph.nodes()],\n",
    "                      dtype=torch.long)\n",
    "\n",
    "data = Data(x=X, edge_index=pyg_data.edge_index, y=labels)\n",
    "train_indices, test_indices = train_test_split(range(data.num_nodes),\n",
    "                                                test_size=0.3,\n",
    "                                                random_state=42)\n",
    "\n",
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.train_mask[train_indices] = True\n",
    "\n",
    "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.test_mask[test_indices] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
    "        super(GINNet, self).__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.conv = GINConv(self.mlp)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lin = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "input_dim = X.size(1)\n",
    "hidden_dim = 32 \n",
    "output_dim = 2 \n",
    "dropout_rate = 0.3\n",
    "\n",
    "model = GINNet(input_dim, hidden_dim, output_dim, dropout=dropout_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = torch.bincount(data.y)\n",
    "total_samples = len(data.y)\n",
    "class_weights = total_samples / (len(class_counts) * class_counts.float())\n",
    "\n",
    "criterion = torch.nn.NLLLoss(weight=class_weights.to(data.y.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "        predictions = output.argmax(dim=1)\n",
    "        correct = predictions[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
    "        accuracy = correct / data.test_mask.sum().item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0, Loss: 0.6832715869\n",
      "Accuracy: 0.68571\n",
      "\n",
      "Epoch 100, Loss: 0.0145142609\n",
      "Accuracy: 0.99441\n",
      "\n",
      "Epoch 200, Loss: 0.0078008100\n",
      "Accuracy: 0.99689\n",
      "\n",
      "Epoch 300, Loss: 0.0039995462\n",
      "Accuracy: 0.99752\n",
      "\n",
      "Stop: Epoch 380, Loss: 0.0027193627\n",
      "Accuracy: 0.99814\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    loss = train()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        accuracy = test()\n",
    "        print(f'\\nEpoch {epoch}, Loss: {loss:.10f}')\n",
    "        print(f'Accuracy: {accuracy:.5f}')\n",
    "\n",
    "    if loss <= 0.005 and test() >= 0.998:\n",
    "        print(f'\\nStop: Epoch {epoch}, Loss: {loss:.10f}')\n",
    "        print(f'Accuracy: {test():.5f}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(y_true, positive_probs):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, positive_probs)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
    "\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred_prob, nodes, mask=None, dataset_name=\"Dataset\"):\n",
    "    if mask is not None:\n",
    "        if isinstance(mask, torch.Tensor):\n",
    "            mask = mask.cpu().numpy()\n",
    "        y_true = y_true[mask]\n",
    "        y_pred_prob = y_pred_prob[mask]\n",
    "        nodes = [node for idx, node in enumerate(nodes) if mask[idx]]\n",
    "\n",
    "    best_threshold = find_best_threshold(y_true, y_pred_prob)\n",
    "    y_pred = (y_pred_prob >= best_threshold).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_true, y_pred_prob)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    fp = conf_matrix[0][1] if conf_matrix.shape[0] > 1 else 0\n",
    "    fn = conf_matrix[1][0] if conf_matrix.shape[0] > 1 else 0\n",
    "\n",
    "    misinformers = [node for node, label in zip(nodes, y_pred) if label == 1]\n",
    "    total_misinformers = sum(y_true)\n",
    "    true_positives = sum(1 for t, p in zip(y_true, y_pred) if t == 1 and p == 1)\n",
    "    percentage_identified = (true_positives / total_misinformers * 100) if total_misinformers > 0 else 0.0\n",
    "\n",
    "    print(f\"\\nEvaluation on {dataset_name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.6f}\")\n",
    "    print(f\"  Precision: {precision:.6f}\")\n",
    "    print(f\"  Recall: {recall:.6f}\")\n",
    "    print(f\"  F1 Score: {f1:.6f}\")\n",
    "    print(f\"  AUC: {auc:.6f}\")\n",
    "    print(f\"  False Positives: {fp}\")\n",
    "    print(f\"  False Negatives: {fn}\")\n",
    "    print(f\"  Number of predicted misinformers ({dataset_name.lower()}): {len(misinformers)}\")\n",
    "    print(f\"  Percentage of misinformers identified ({dataset_name.lower()}): {percentage_identified:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on Test Set:\n",
      "  Accuracy: 0.999379\n",
      "  Precision: 1.000000\n",
      "  Recall: 0.976190\n",
      "  F1 Score: 0.987952\n",
      "  AUC: 0.998132\n",
      "  False Positives: 0\n",
      "  False Negatives: 1\n",
      "  Number of predicted misinformers (test set): 41\n",
      "  Percentage of misinformers identified (test set): 97.61905%\n",
      "\n",
      "Evaluation on Complete Set:\n",
      "  Accuracy: 0.999627\n",
      "  Precision: 0.992424\n",
      "  Recall: 0.992424\n",
      "  F1 Score: 0.992424\n",
      "  AUC: 0.999440\n",
      "  False Positives: 1\n",
      "  False Negatives: 1\n",
      "  Number of predicted misinformers (complete set): 132\n",
      "  Percentage of misinformers identified (complete set): 99.24242%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "    y_prob = torch.exp(output)[:, 1].cpu().numpy()\n",
    "    y_true = data.y.cpu().numpy()\n",
    "    node_list = list(graph.nodes())\n",
    "\n",
    "evaluate_model(\n",
    "    y_true=y_true,\n",
    "    y_pred_prob=y_prob,\n",
    "    nodes=node_list,\n",
    "    mask=data.test_mask,\n",
    "    dataset_name=\"Test Set\"\n",
    ")\n",
    "\n",
    "evaluate_model(\n",
    "    y_true=y_true,\n",
    "    y_pred_prob=y_prob,\n",
    "    nodes=node_list,\n",
    "    mask=None,\n",
    "    dataset_name=\"Complete Set\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
